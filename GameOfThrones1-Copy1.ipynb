{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import en_core_web_sm\n",
    "import math\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Prologue\n",
      "2 Bran\n",
      "3 Catelyn\n",
      "4 Daenerys\n",
      "5 Eddard\n",
      "6 Jon\n",
      "7 Catelyn\n",
      "8 Arya\n",
      "9 Bran\n",
      "10 Tyrion\n",
      "11 Jon\n",
      "12 Daenerys\n",
      "13 Eddard\n",
      "14 Tyrion\n",
      "15 Catelyn\n",
      "16 Sansa\n",
      "17 Eddard\n",
      "18 Bran\n",
      "19 Catelyn\n",
      "20 Jon\n",
      "21 Eddard\n",
      "22 Tyrion\n",
      "23 Arya\n",
      "24 Daenerys\n",
      "25 Bran\n",
      "26 Eddard\n",
      "27 Jon\n",
      "28 Eddard\n",
      "29 Catelyn\n",
      "30 Sansa\n",
      "31 Eddard\n",
      "32 Tyrion\n",
      "33 Arya\n",
      "34 Eddard\n",
      "35 Catelyn\n",
      "36 Eddard\n",
      "37 Daenerys\n",
      "38 Bran\n",
      "39 Tyrion\n",
      "40 Eddard\n",
      "41 Catelyn\n",
      "42 Jon\n",
      "43 Tyrion\n",
      "44 Eddard\n",
      "45 Sansa\n",
      "46 Eddard\n",
      "47 Daenerys\n",
      "48 Eddard\n",
      "49 Jon\n",
      "50 Eddard\n",
      "51 Arya\n",
      "52 Sansa\n",
      "53 Jon\n",
      "54 Bran\n",
      "55 Daenerys\n",
      "56 Catelyn\n",
      "57 Tyrion\n",
      "58 Sansa\n",
      "59 Eddard\n",
      "60 Catelyn\n",
      "61 Jon\n",
      "62 Daenerys\n",
      "63 Tyrion\n",
      "64 Catelyn\n",
      "65 Daenerys\n",
      "66 Arya\n",
      "67 Bran\n",
      "68 Sansa\n",
      "69 Daenerys\n",
      "70 Tyrion\n",
      "71 Jon\n",
      "72 Catelyn\n",
      "73 Daenerys\n"
     ]
    }
   ],
   "source": [
    "##Open text with the first book\n",
    "##Chapters is a list which contains all the chapters ; we the .split() function which detect all times with 5 new line\n",
    "\n",
    "with open('GOT1.txt','r') as fp:\n",
    "    book = fp.read()\n",
    "    chapters = book.split('\\n\\n\\n\\n\\n')\n",
    "    sm = []\n",
    "    for i in range(0,len(chapters)):\n",
    "        name = [word for word in chapters[i].split('\\n') if len(word.strip())>0][0]\n",
    "        print (i+1,name.title())\n",
    "        chapter = ' '.join([word.replace('\\t','').replace('\"','') for word in chapters[i].split('\\n') if len(word.strip())>0][1:])\n",
    "                           \n",
    "        doc1 = nlp(chapter)\n",
    "        for ent in doc1.ents:\n",
    "            if ent.label_ == 'PERSON' :\n",
    "                sm.append((ent.text, ent.start_char, ent.end_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open ('GOT-characters-raw.pickle','rb') as ch:\n",
    "    characters=pickle.load(ch)  \n",
    "len(characters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5522\n"
     ]
    }
   ],
   "source": [
    "entities = set()\n",
    "for chapter in characters.values():\n",
    "    for entity in chapter:\n",
    "        name=entity[0]\n",
    "        entities.add(name)\n",
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOT=nx.Graph()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 0\n",
      "Number of edges: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(GOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter=characters['1–1-Bran']\n",
    "chapter.sort(key=lambda a:a[1],reverse=False)\n",
    "\n",
    "def get_edges_from_chapter(chapter):\n",
    "    chapter.sort(key = lambda a:a[1], reverse = False) #trier perso par postiion dans le texte\n",
    "\n",
    "    potential_edges = []\n",
    "\n",
    "    for i in range(0, len(chapter)): #balaye tout les perso\n",
    "        name1, start1, end1 = chapter[i] #rebalaye et lien avec ceux d'après\n",
    "        for j in range(i+1, len(chapter)):\n",
    "            name2, start2, end2 = chapter[j]\n",
    "            if name2 != name1:\n",
    "                potential_edges.append((name1,name2,{'dist':start2-end1}))\n",
    "    edges = {}\n",
    "    for name1,name2,value in potential_edges:\n",
    "        if (name1,name2) not in edges.keys():\n",
    "            if (name2,name1) not in edges.keys():\n",
    "                edges[(name1,name2)] = {'values':[value['dist']]}\n",
    "            else:\n",
    "                edges[(name2,name1)]['values'].append(value['dist'])\n",
    "        else:\n",
    "            edges[(name1,name2)]['values'].append(value['dist'])\n",
    "\n",
    "    for k,v in edges.items():\n",
    "        #edges[k]['weight']=np.percentile(v['values'],10)\n",
    "        edges[k]['weight']=len([a for a in v['values'] if a < 1000])\n",
    "        #print (k, edges[k]['weight'])\n",
    "    \n",
    "    ready_for_nx =[]\n",
    "    for k,v in edges.items():\n",
    "        name1 = k[0]\n",
    "        name2 = k[1]\n",
    "        weight = v['weight']\n",
    "        if weight>0:\n",
    "            ready_for_nx.append((name1, name2, weight))\n",
    "    return ready_for_nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-229cd799289e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchapter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcharacters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mGOT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_edges_from_chapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/networkx/classes/graph.py\u001b[0m in \u001b[0;36madd_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mdatadict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mdatadict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0mdatadict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for chapter in characters.values():\n",
    "    GOT.add_edges_from(get_edges_from_chapter(chapter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 2\n",
      "Number of edges: 0\n",
      "Average degree:   0.0000\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(GOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
